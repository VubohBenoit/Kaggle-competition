{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fbcf2-a8de-4bbc-a996-dd71c76e1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Charger les données avec types de colonnes optimisés\n",
    "data_path = \"competition-data/\"  # En local\n",
    "#data_path = \"/kaggle/input/competition-epsi-2025-ds-ml-g-3-g-4/\"  # Sur Kaggle\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "\n",
    "# Fonction pour rechercher les valeurs manquantes\n",
    "def missing_values(data):\n",
    "    print(\"\\n--- Valeurs manquantes ---\")\n",
    "    missing = data.isnull().sum()  \n",
    "    missing_percentage = (missing / len(data)) * 100  \n",
    "    missing_info = pd.DataFrame({'Valeurs manquantes': missing, 'Pourcentage': missing_percentage})\n",
    "    print(missing_info[missing_info['Valeurs manquantes'] > 0])  \n",
    "    return missing_info\n",
    "\n",
    "# Fonction pour rechercher et traiter les valeurs aberrantes\n",
    "def handle_outliers(data):\n",
    "    print(\"\\n--- Valeurs aberrantes ---\")\n",
    "    numeric_columns = data.select_dtypes(include=[np.number]).columns  \n",
    "    for col in numeric_columns:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"\\nColonne : {col}\")\n",
    "            print(f\"Valeurs aberrantes : {outliers.shape[0]}\")\n",
    "            \n",
    "            # Utilisation de PowerTransformer pour normaliser les données\n",
    "            transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "            data[col] = transformer.fit_transform(data[col].values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            print(f\"\\nColonne : {col} : Pas de valeurs aberrantes détectées.\")\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    df['BMI'] = df['weight(kg)'] / (df['height(cm)'] / 100) ** 2\n",
    "    df['Cholesterol_Ratio'] = df['HDL'] / df['LDL']\n",
    "    df['Eyesight_Diff'] = df['eyesight(left)'] - df['eyesight(right)']\n",
    "    df['log_triglyceride'] = np.log1p(df['triglyceride'])\n",
    "    df['AST_ALT_Ratio'] = df['AST'] / df['ALT']\n",
    "    \n",
    "    # Interaction Features\n",
    "    df['Weight_Height_Interaction'] = df['weight(kg)'] * df['height(cm)']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer le Feature Engineering\n",
    "train_data = feature_engineering(train_data)\n",
    "test_data = feature_engineering(test_data)\n",
    "\n",
    "# Séparer les caractéristiques et la cible\n",
    "X = train_data.drop(columns=['id', 'smoking'])\n",
    "y = train_data['smoking']\n",
    "\n",
    "# Normalisation et traitement des outliers\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test_data.drop(columns=['id']))\n",
    "\n",
    "# Division en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE pour gérer les données déséquilibrées\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Sélection de caractéristiques avec XGBoost\n",
    "selector = SelectFromModel(XGBClassifier(random_state=42), threshold='median')\n",
    "X_train_selected = selector.fit_transform(X_train_res, y_train_res)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "test_selected = selector.transform(test_scaled)\n",
    "\n",
    "# Optimisation des hyperparamètres pour XGBoost avec RandomizedSearchCV\n",
    "param_dist_xgb = {\n",
    "    'learning_rate': stats.uniform(0.01, 0.3),\n",
    "    'max_depth': stats.randint(3, 10),\n",
    "    'n_estimators': stats.randint(100, 600),\n",
    "    'subsample': stats.uniform(0.6, 0.4),\n",
    "    'colsample_bytree': stats.uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=42), \n",
    "    param_distributions=param_dist_xgb, \n",
    "    n_iter=50, \n",
    "    cv=3, \n",
    "    scoring='roc_auc', \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search_xgb.fit(X_train_selected, y_train_res)\n",
    "print(f\"Meilleurs hyperparamètres (XGBoost - Randomized) : {random_search_xgb.best_params_}\")\n",
    "\n",
    "# Entraîner le modèle XGBoost avec les meilleurs hyperparamètres\n",
    "xgb = XGBClassifier(**random_search_xgb.best_params_, random_state=42)\n",
    "xgb.fit(X_train_selected, y_train_res)\n",
    "\n",
    "# Ajouter d'autres modèles avec leurs propres optimisations\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(algorithm='SAMME', random_state=42)\n",
    "\n",
    "# Ensembling avec Stacking\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb),\n",
    "        ('rf', rf),\n",
    "        ('gbm', gbm),\n",
    "        ('ada', ada)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Calibration des probabilités\n",
    "calibrated_model = CalibratedClassifierCV(stacking_model, method='isotonic', cv=5)\n",
    "calibrated_model.fit(X_train_selected, y_train_res)\n",
    "\n",
    "# Validation Croisée Stratifiée\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(calibrated_model, X_train_selected, y_train_res, cv=stratified_kfold, scoring='roc_auc')\n",
    "print(f'AUC-ROC moyenne (Validation Croisée Stratifiée) : {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391be51-2d63-4374-9e4b-a3b7b48f61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur l'ensemble de test\n",
    "test_pred_proba_calibrated = calibrated_model.predict_proba(test_selected)[:, 1]\n",
    "\n",
    "# Préparation du fichier de soumission\n",
    "submission = pd.DataFrame({'id': test_data['id'], 'smoking': test_pred_proba_calibrated})\n",
    "submission.to_csv('submission_final_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
